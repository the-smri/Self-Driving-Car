<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/d5bac278-9b78-442e-9c36-8b2a9a74ca1b" />


# ğŸš— Autonomous Car Path Following Simulation

This project simulates a **self-driving Tesla car** navigating a predefined track using **color-based detection and decision logic** â€” all in a simple 2D environment.
Itâ€™s not just a game â€” itâ€™s an **educational demo** of real-world autonomous vehicle concepts!

---

## ğŸ® Overview

The simulation:

* ğŸ›£ï¸ Creates a **track** with a **white path** on a **dark background**
* ğŸš˜ Places a **Tesla car sprite** that **follows the path automatically**
* ğŸ¨ Uses **color detection (RGB 255,255,255)** to detect and follow the white path
* âš¡ Includes **collision detection points** (up, down, right) to sense track boundaries
* ğŸ”„ Executes **90Â° turns** automatically when detecting intersections
* ğŸŸ¢ Displays a **green dot sensor**, representing the carâ€™s â€œcameraâ€ or vision system

---

## ğŸ§  What Makes It Special?

This isnâ€™t just a toy simulation â€” itâ€™s inspired by **real autonomous vehicle engineering** concepts.

### âœ… Real-World Principles Simulated:

* **Sensor-Based Navigation** â€” mimics how real self-driving cars use cameras or LiDAR
* **Path Following Algorithms** â€” continuous feedback-based motion control
* **Decision Making** â€” handles intersections logically
* **Collision Avoidance** â€” prevents the car from leaving the track

### âŒ Game-Like Simplifications:

* Simple **2D environment**
* **Color-based detection** instead of real sensor input
* **Predefined track** with fixed paths

---

## ğŸ“ Educational Value

This project can be used for:

* ğŸ§© **Teaching** basic concepts of autonomous navigation
* ğŸ’¡ **Prototyping** path-following and sensor algorithms
* ğŸ¤– **Understanding** how sensors detect and react to environmental data
* ğŸŒ³ **Learning** decision-tree logic in robotics

---

## ğŸ› ï¸ Technologies Used

* **Python** (e.g., with Pygame or OpenCV â€” depending on implementation)
* **2D Graphics & Sprite Handling**
* **Basic Computer Vision (Color Thresholding)**

---

## ğŸš€ How It Works

1. The track image provides a **white path** for the car to follow.
2. The carâ€™s virtual â€œcameraâ€ (green dot) continuously reads color values ahead.
3. When the camera detects white (`RGB(255,255,255)`), it moves forward.
4. When a sensor detects a dark area or an intersection, the car makes a **90Â° turn**.
5. This feedback loop allows the car to autonomously navigate the entire track.

---

## ğŸ“˜ Future Enhancements

* Add **dynamic obstacles** and real-time avoidance
* Use **PID control** for smoother path following
* Implement **neural networks** for adaptive navigation
* Introduce **multiple cars** to simulate traffic

---

## ğŸ“„ License

This project is released for **educational and research purposes**.
You are free to **use, modify, and share** it with proper credit.

